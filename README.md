# ğŸš€ LocalAI Stack Project

A comprehensive, privacy-first AI infrastructure stack that runs entirely on your local environment. This monorepo combines a modern Next.js frontend, Python-based AI search agent, and containerized AI services for a complete local AI experience.

## âœ¨ Features

- ğŸ”’ **Privacy-First**: All AI processing happens locally on your infrastructure
- ğŸ¨ **Modern UI**: Futuristic Next.js frontend with glassmorphism and neon effects
- ğŸ¤– **Multiple AI Models**: Support for DeepSeek R1, Qwen 3, and other Ollama models
- ğŸ” **AI-Powered Search**: Intelligent web search with SearXNG and local AI analysis
- ğŸ’¬ **Real-time Chat**: Live chat interface with local LLM models
- ğŸ“Š **Observability**: Integrated monitoring with Langfuse and Prometheus
- ğŸ³ **Containerized**: Complete Docker-based deployment
- ğŸŒ©ï¸ **Cloud Ready**: Terraform scripts for production deployment

## ğŸ“ Project Structure

```
local-ai-stack/
â”œâ”€â”€ apps/                           # Frontend applications
â”‚   â”œâ”€â”€ web/                        # Next.js web application
â”‚   â””â”€â”€ api/                        # API services
â”œâ”€â”€ packages/                       # Shared packages
â”‚   â”œâ”€â”€ ui/                         # Reusable UI components (shadcn/ui)
â”‚   â”œâ”€â”€ eslint-config/              # Shared ESLint configuration
â”‚   â””â”€â”€ typescript-config/          # Shared TypeScript configuration
â”œâ”€â”€ services/                       # Backend services
â”‚   â””â”€â”€ ai-search-agent/            # Python AI search service
â”œâ”€â”€ deployment/                     # Deployment configurations
â”‚   â”œâ”€â”€ terraform/                  # Infrastructure as Code
â”‚   â””â”€â”€ monitoring/                 # Monitoring stack
â””â”€â”€ docs/                          # Documentation
```

## ğŸš€ Quick Start

### Prerequisites

- **Node.js 20+** and **pnpm** (latest)
- **Docker** and **Docker Compose**
- **Ollama** for local AI models
- **Supabase** account (for authentication and data storage)

### 1. Clone and Install

```bash
git clone <repository-url>
cd local-ai-stack
pnpm install
```

### 2. Set Up Local AI Infrastructure

Follow our comprehensive setup guide:

```bash
# See detailed instructions in docs/LOCAL_AI_SETUP_GUIDE.md
```

**Key components to install:**
- Ollama with AI models (DeepSeek R1, Qwen 3)
- Open Web UI (AI chat interface)
- SearXNG (privacy-focused search engine)

### 3. Configure Environment

**Frontend Configuration:**
```bash
cd apps/web
cp .env.example .env.local
```

Edit `.env.local`:
```env
# Supabase Configuration
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key

# Open Web UI Configuration
NEXT_PUBLIC_OPENWEBUI_URL=http://localhost:3000

# AI Search Agent
NEXT_PUBLIC_AI_SEARCH_URL=http://localhost:8001
```

**AI Search Agent Configuration:**
```bash
cd services/ai-search-agent
cp .env.example .env
```

### 4. Start Development

**Option A: Start Everything**
```bash
pnpm dev
```

**Option B: Start Individual Services**
```bash
# Frontend
cd apps/web && pnpm dev

# AI Search Agent
cd services/ai-search-agent && docker-compose up -d
```

## ğŸ—ï¸ Architecture

### Frontend Stack
- **Framework**: Next.js 15 with App Router
- **Styling**: Tailwind CSS with shadcn/ui components
- **State Management**: React hooks and context
- **Authentication**: Supabase Auth
- **Database**: Supabase PostgreSQL

### Backend Stack
- **AI Search**: FastAPI with SearXNG integration
- **LLM Integration**: Ollama for local model inference
- **Caching**: Redis for performance optimization
- **Observability**: Langfuse for AI monitoring
- **Metrics**: Prometheus and Grafana

### Infrastructure
- **Containerization**: Docker and Docker Compose
- **Orchestration**: Turbo for monorepo management
- **Deployment**: Terraform for cloud infrastructure
- **Monitoring**: Prometheus, Grafana, Langfuse stack

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [Frontend Setup](docs/FRONTEND_SETUP.md) | Complete frontend installation and configuration |
| [Local AI Setup](docs/LOCAL_AI_SETUP_GUIDE.md) | Comprehensive local AI infrastructure setup |
| [Cloud Deployment](deployment/CLOUD_DEPLOYMENT.md) | Production deployment guide |
| [Observability](deployment/LANGFUSE_OBSERVABILITY.md) | Monitoring and observability setup |
| [Performance](deployment/PERFORMANCE_OPTIMIZATION.md) | Performance optimization guide |

## ğŸ› ï¸ Available Scripts

### Root Level
```bash
pnpm dev          # Start all development servers
pnpm build        # Build all applications
pnpm lint         # Lint all packages
pnpm format       # Format code with Prettier
```

### Frontend (apps/web)
```bash
pnpm dev          # Start Next.js development server
pnpm build        # Build production application
pnpm start        # Start production server
pnpm lint         # Lint frontend code
```

### AI Search Agent (services/ai-search-agent)
```bash
./setup.sh        # Initial setup (Linux/macOS)
./setup.ps1       # Initial setup (Windows)
docker-compose up # Start AI search services
```

## ğŸš€ Deployment

### Local Development
1. Follow the [Local AI Setup Guide](docs/LOCAL_AI_SETUP_GUIDE.md)
2. Run `pnpm dev` in the project root
3. Access the application at `http://localhost:3001`

### Production Deployment
1. Review [Cloud Deployment Guide](deployment/CLOUD_DEPLOYMENT.md)
2. Configure Terraform variables
3. Run deployment scripts:

**Linux/macOS:**
```bash
cd deployment && ./deploy.sh
```

**Windows:**
```powershell
cd deployment && .\deploy.ps1 -Action full
```

## ğŸ”§ Configuration

### Environment Variables

**Frontend (apps/web/.env.local):**
- `NEXT_PUBLIC_SUPABASE_URL` - Supabase project URL
- `NEXT_PUBLIC_SUPABASE_ANON_KEY` - Supabase anonymous key
- `NEXT_PUBLIC_OPENWEBUI_URL` - Open Web UI endpoint
- `NEXT_PUBLIC_AI_SEARCH_URL` - AI Search Agent endpoint

**AI Search Agent (services/ai-search-agent/.env):**
- `OLLAMA_BASE_URL` - Ollama API endpoint
- `SEARXNG_URL` - SearXNG search engine URL
- `REDIS_URL` - Redis cache connection string
- `LANGFUSE_SECRET_KEY` - Langfuse observability key

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add amazing feature'`
4. Push to the branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

### Development Guidelines

- Follow the existing code style and formatting
- Add tests for new features
- Update documentation as needed
- Ensure all CI checks pass

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) - Local LLM inference
- [SearXNG](https://searxng.org/) - Privacy-focused search
- [Supabase](https://supabase.com/) - Backend as a Service
- [shadcn/ui](https://ui.shadcn.com/) - Beautiful UI components
- [Langfuse](https://langfuse.com/) - AI observability platform

## ğŸ“ Support

- ğŸ“– Check the [documentation](docs/)
- ğŸ› Report bugs via [GitHub Issues]
- ğŸ’¬ Join our community discussions
- ğŸ“§ Contact the maintainers

---

**Built with â¤ï¸ for the privacy-conscious AI community**